{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RCNN using fasttext.ipynb","provenance":[],"authorship_tag":"ABX9TyPHR1YPhZA7F7G3KIDe8u8N"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"esTASulJXHaq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"81ccd57e-7cd2-45af-96eb-3cbacd1378f7","executionInfo":{"status":"ok","timestamp":1591816827660,"user_tz":-330,"elapsed":844,"user":{"displayName":"Shubham Kumar","photoUrl":"","userId":"13299555443270476721"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6Dmhb3YEXr5k","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"031c6b8e-ae24-4123-c163-1c8823e574f5","executionInfo":{"status":"ok","timestamp":1591816828461,"user_tz":-330,"elapsed":1610,"user":{"displayName":"Shubham Kumar","photoUrl":"","userId":"13299555443270476721"}}},"source":["cd /content/drive/My Drive"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xbrIOPSQXso_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"fe94af2f-2225-4e0c-ec31-34b7460f658b","executionInfo":{"status":"ok","timestamp":1591816831243,"user_tz":-330,"elapsed":4362,"user":{"displayName":"Shubham Kumar","photoUrl":"","userId":"13299555443270476721"}}},"source":["import os\n","import sys\n","import numpy as np\n","import pandas as pd\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","\n","from gensim.models import KeyedVectors"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"3niwjCsQXsqp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":323},"outputId":"f44a7d4a-af84-4a0d-cf44-512ab5e13fda","executionInfo":{"status":"ok","timestamp":1591816834857,"user_tz":-330,"elapsed":7958,"user":{"displayName":"Shubham Kumar","photoUrl":"","userId":"13299555443270476721"}}},"source":["reviews_df = pd.read_csv('Hotel_Reviews.csv')\n","print(reviews_df.dtypes)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Hotel_Address                                  object\n","Additional_Number_of_Scoring                    int64\n","Review_Date                                    object\n","Average_Score                                 float64\n","Hotel_Name                                     object\n","Reviewer_Nationality                           object\n","Negative_Review                                object\n","Review_Total_Negative_Word_Counts               int64\n","Total_Number_of_Reviews                         int64\n","Positive_Review                                object\n","Review_Total_Positive_Word_Counts               int64\n","Total_Number_of_Reviews_Reviewer_Has_Given      int64\n","Reviewer_Score                                float64\n","Tags                                           object\n","days_since_review                              object\n","lat                                           float64\n","lng                                           float64\n","dtype: object\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K9mSyboMXswB","colab_type":"code","colab":{}},"source":["def clean(text):\n","    '''\n","    '''\n","    text = text.lower()\n","    text = text.replace(\"ain't\", \"am not\")\n","    text = text.replace(\"aren't\", \"are not\")\n","    text = text.replace(\"can't\", \"cannot\")\n","    text = text.replace(\"can't've\", \"cannot have\")\n","    text = text.replace(\"'cause\", \"because\")\n","    text = text.replace(\"could've\", \"could have\")\n","    text = text.replace(\"couldn't\", \"could not\")\n","    text = text.replace(\"couldn't've\", \"could not have\")\n","    text = text.replace(\"should've\", \"should have\")\n","    text = text.replace(\"should't\", \"should not\")\n","    text = text.replace(\"should't've\", \"should not have\")\n","    text = text.replace(\"would've\", \"would have\")\n","    text = text.replace(\"would't\", \"would not\")\n","    text = text.replace(\"would't've\", \"would not have\")\n","    text = text.replace(\"didn't\", \"did not\")\n","    text = text.replace(\"doesn't\", \"does not\")\n","    text = text.replace(\"don't\", \"do not\")\n","    text = text.replace(\"hadn't\", \"had not\")\n","    text = text.replace(\"hadn't've\", \"had not have\")\n","    text = text.replace(\"hasn't\", \"has not\")\n","    text = text.replace(\"haven't\", \"have not\")\n","    text = text.replace(\"haven't\", \"have not\")\n","    text = text.replace(\"haven't\", \"have not\")\n","    text = text.replace(\"haven't\", \"have not\")\n","    text = text.replace(\"he'd\", \"he would\")\n","    text = text.replace(\"haven't\", \"have not\")\n","    text = text.replace(\"he'd've\", \"he would have\")\n","    text = text.replace(\"'s\", \"\")\n","    text = text.replace(\"'t\", \"\")\n","    text = text.replace(\"'ve\", \"\")\n","    text = text.replace(\".\", \" . \")\n","    text = text.replace(\"!\", \" ! \")\n","    text = text.replace(\"?\", \" ? \")\n","    text = text.replace(\";\", \" ; \")\n","    text = text.replace(\":\", \" : \")\n","    text = text.replace(\",\", \" , \")\n","    text = text.replace(\"´\", \"\")\n","    text = text.replace(\"‘\", \"\")\n","    text = text.replace(\"’\", \"\")\n","    text = text.replace(\"“\", \"\")\n","    text = text.replace(\"”\", \"\")\n","    text = text.replace(\"\\'\", \"\")\n","    text = text.replace(\"\\\"\", \"\")\n","    text = text.replace(\"-\", \"\")\n","    text = text.replace(\"–\", \"\")\n","    text = text.replace(\"—\", \"\")\n","    text = text.replace(\"[\", \"\")\n","    text = text.replace(\"]\",\"\")\n","    text = text.replace(\"{\",\"\")\n","    text = text.replace(\"}\", \"\")\n","    text = text.replace(\"/\", \"\")\n","    text = text.replace(\"|\", \"\")\n","    text = text.replace(\"(\", \"\")\n","    text = text.replace(\")\", \"\")\n","    text = text.replace(\"$\", \"\")\n","    text = text.replace(\"+\", \"\")\n","    text = text.replace(\"*\", \"\")\n","    text = text.replace(\"%\", \"\")\n","    text = text.replace(\"#\", \"\")\n","    text = text.replace(\"\\n\", \" \\n \")\n","    text = text.replace(\"\\n\", \"\")\n","    text = text.replace(\"_\", \" _ \")\n","    text = text.replace(\"_\", \"\")\n","    text = ''.join([i for i in text if not i.isdigit()])\n","\n","    return text\n","\n","positive_reviews = reviews_df['Positive_Review'].values\n","negative_reviews = reviews_df['Negative_Review'].values\n","\n","cleaned_positive_reviews = [clean(r) for r in positive_reviews] \n","cleaned_negative_reviews = [clean(r) for r in negative_reviews] \n","\n","reviews_df['Positive_Review'] = cleaned_positive_reviews\n","reviews_df['Negative_Review'] = cleaned_negative_reviews"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0KWBwVrcXs6L","colab_type":"code","colab":{}},"source":["# Shuffling data\n","reviews_df = reviews_df.sample(frac=1).reset_index(drop=True)\n","\n","# Extracting all text\n","positive_reviews = reviews_df['Positive_Review'].values\n","negative_reviews = reviews_df['Negative_Review'].values\n","reviews_text = []\n","\n","for p,n in zip(positive_reviews, negative_reviews) : \n","    if p in ['na', 'nothing', 'none', 'n a', 'no', 'no positive', 'no negative'] : \n","        reviews_text.append(n)\n","    elif n in ['na', 'nothing', 'none', 'n a', 'no', 'no positive', 'no negative'] : \n","        reviews_text.append(p)\n","    else : \n","        reviews_text.append(n)\n","        reviews_text.append(p)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CIqMnmsYXs9g","colab_type":"code","colab":{}},"source":["# Preprocessing training data\n","training_df = reviews_df.loc[:10000]\n","positive_reviews_filtered = training_df['Positive_Review'].values\n","negative_reviews_filtered = training_df['Negative_Review'].values\n","training_reviews = []\n","labels = []\n","\n","for idx,(p,n) in enumerate(zip(positive_reviews_filtered, negative_reviews_filtered)) : \n","    if p in ['na', 'nothing', 'none', 'n a', 'no', 'no positive', 'no negative'] : \n","        training_reviews.append(n)\n","        labels.append(0)\n","    elif n in ['na', 'nothing', 'none', 'n a', 'no', 'no positive', 'no negative'] :\n","        training_reviews.append(p)\n","        labels.append(1)\n","    else :\n","        training_reviews.append(n)\n","        labels.append(0)\n","        training_reviews.append(p)\n","        labels.append(1)\n","\n","# Creating datasets\n","dict1 ={\n","    'reviews' : training_reviews,\n","    'labels' : labels\n","}\n","sentiment_df = pd.DataFrame.from_dict(dict1)\n","\n","\n","dict2 ={\n","    'reviews_text' : reviews_text\n","}\n","reviews_text_df = pd.DataFrame.from_dict(dict2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n86aZi6qXtD1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"2ef30625-d7bf-4502-ec00-2b2dd6669af5","executionInfo":{"status":"ok","timestamp":1591816858769,"user_tz":-330,"elapsed":31813,"user":{"displayName":"Shubham Kumar","photoUrl":"","userId":"13299555443270476721"}}},"source":["tokenizer = Tokenizer(num_words=500)\n","tokenizer.fit_on_texts(training_reviews)\n","sequences = tokenizer.texts_to_sequences(training_reviews)\n","\n","word_index = tokenizer.word_index\n","print('Found %s unique tokens.' % len(word_index))\n","\n","MAX_SEQUENCE_LENGTH = 500\n","\n","data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","\n","\n","labels = to_categorical(np.asarray(labels))\n","print('Shape of data tensor:', data.shape)\n","print('Shape of label tensor:', labels.shape)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Found 10989 unique tokens.\n","Shape of data tensor: (16821, 500)\n","Shape of label tensor: (16821, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G4yJ__IVXtJP","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","x_train, x_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)\n","x_test, x_val, y_test, y_val = train_test_split(data, labels, test_size=0.5, random_state=42)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uaK19rXAXtOk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":323},"outputId":"ff0ef89a-4e3a-4f60-92fc-ae3a13416d8b","executionInfo":{"status":"ok","timestamp":1591816972093,"user_tz":-330,"elapsed":145103,"user":{"displayName":"Shubham Kumar","photoUrl":"","userId":"13299555443270476721"}}},"source":["!wget https://drive.google.com/open?id=1xzt06g_xeP1DitFXhJprF5VTwzNEUYhq\n","!unzip wiki-news-300d-1M.vec.zip\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["--2020-06-10 19:20:59--  https://drive.google.com/open?id=1xzt06g_xeP1DitFXhJprF5VTwzNEUYhq\n","Resolving drive.google.com (drive.google.com)... 173.194.217.138, 173.194.217.139, 173.194.217.100, ...\n","Connecting to drive.google.com (drive.google.com)|173.194.217.138|:443... connected.\n","HTTP request sent, awaiting response... 307 Temporary Redirect\n","Location: https://drive.google.com/file/d/1xzt06g_xeP1DitFXhJprF5VTwzNEUYhq/view?usp=drive_open [following]\n","--2020-06-10 19:20:59--  https://drive.google.com/file/d/1xzt06g_xeP1DitFXhJprF5VTwzNEUYhq/view?usp=drive_open\n","Reusing existing connection to drive.google.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [text/html]\n","Saving to: ‘open?id=1xzt06g_xeP1DitFXhJprF5VTwzNEUYhq.10’\n","\n","\r          open?id=1     [<=>                 ]       0  --.-KB/s               \ropen?id=1xzt06g_xeP     [ <=>                ]  68.21K  --.-KB/s    in 0.009s  \n","\n","2020-06-10 19:20:59 (7.20 MB/s) - ‘open?id=1xzt06g_xeP1DitFXhJprF5VTwzNEUYhq.10’ saved [69843]\n","\n","Archive:  wiki-news-300d-1M.vec.zip\n","replace wiki-news-300d-1M.vec? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n","  inflating: wiki-news-300d-1M.vec   \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TF9cDLQvXtTs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"73e657d4-e1cf-47c6-c923-89c995035b25","executionInfo":{"status":"ok","timestamp":1591817249004,"user_tz":-330,"elapsed":421995,"user":{"displayName":"Shubham Kumar","photoUrl":"","userId":"13299555443270476721"}}},"source":["model_ft = KeyedVectors.load_word2vec_format('wiki-news-300d-1M.vec', binary=False)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"c98qqh-7XtZx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"b47dfd84-f09d-4516-e90c-a888c659f9e3","executionInfo":{"status":"ok","timestamp":1591817249013,"user_tz":-330,"elapsed":421986,"user":{"displayName":"Shubham Kumar","photoUrl":"","userId":"13299555443270476721"}}},"source":["EMBEDDING_DIM = 300\n","MAX_NUM_WORDS=500\n","print('Preparing embedding matrix.fast text')\n","\n","# prepare embedding matrix\n","num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n","embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n","for word, i in word_index.items():\n","    if i >= MAX_NUM_WORDS:\n","        continue\n","    if word in model_ft.vocab:\n","      embedding_vector = model_ft[word]\n","      embedding_vector = np.array(embedding_vector)\n","      if embedding_vector is not None:\n","          # words not found in embedding index will be all-zeros.\n","          embedding_matrix[i] = embedding_vector\n","print(embedding_matrix.shape)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Preparing embedding matrix.fast text\n","(500, 300)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qp54xU3aXtYF","colab_type":"code","colab":{}},"source":["import keras\n","from keras.preprocessing import sequence\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation\n","from keras.layers import Embedding\n","from keras.layers import GRU\n","from keras.layers import LSTM\n","\n","from keras.layers import Conv2D, MaxPooling1D\n","from keras.datasets import imdb\n","from sklearn.datasets import fetch_20newsgroups\n","import numpy as np\n","from sklearn import metrics\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.initializers import Constant\n","maxlen=40\n","max_features=40000\n","batch_size=32\n","filters = 256\n","pool_size = 2\n","gru_node = 256\n","\n","model=keras.models.Sequential()\n","model.add(keras.layers.Embedding(num_words,\n","                            EMBEDDING_DIM,\n","                            embeddings_initializer=Constant(embedding_matrix),\n","                            input_length=MAX_SEQUENCE_LENGTH,\n","                            trainable=False))\n","model.add(Dropout(0.25))\n","model.add(Conv1D(filters, kernel_size=2, activation='relu'))\n","model.add(MaxPooling1D(pool_size=pool_size))\n","model.add(Conv1D(filters, kernel_size=2, activation='relu'))\n","model.add(MaxPooling1D(pool_size=pool_size))\n","model.add(Conv1D(filters, kernel_size=2, activation='relu'))\n","model.add(MaxPooling1D(pool_size=pool_size))\n","model.add(Conv1D(filters, kernel_size=2, activation='relu'))\n","model.add(MaxPooling1D(pool_size=pool_size))\n","model.add(LSTM(gru_node, return_sequences=True, recurrent_dropout=0.2))\n","model.add(LSTM(gru_node, return_sequences=True, recurrent_dropout=0.2))\n","model.add(LSTM(gru_node, return_sequences=True, recurrent_dropout=0.2))\n","model.add(LSTM(gru_node, recurrent_dropout=0.2))\n","model.add(Dense(128,activation='relu'))\n","model.add(Dense(2, activation='softmax'))\n","\n","model.compile(loss='sparse_categorical_crossentropy',\n","                  optimizer='adam',\n","                  metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UyDOPmkPXtSY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":697},"outputId":"7253bfea-e122-4cd0-abc4-35c8c7e3644c","executionInfo":{"status":"ok","timestamp":1591817690840,"user_tz":-330,"elapsed":1616,"user":{"displayName":"Shubham Kumar","photoUrl":"","userId":"13299555443270476721"}}},"source":["model.summary()"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_7 (Embedding)      (None, 500, 300)          150000    \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 500, 300)          0         \n","_________________________________________________________________\n","conv1d_13 (Conv1D)           (None, 499, 256)          153856    \n","_________________________________________________________________\n","max_pooling1d_13 (MaxPooling (None, 249, 256)          0         \n","_________________________________________________________________\n","conv1d_14 (Conv1D)           (None, 248, 256)          131328    \n","_________________________________________________________________\n","max_pooling1d_14 (MaxPooling (None, 124, 256)          0         \n","_________________________________________________________________\n","conv1d_15 (Conv1D)           (None, 123, 256)          131328    \n","_________________________________________________________________\n","max_pooling1d_15 (MaxPooling (None, 61, 256)           0         \n","_________________________________________________________________\n","conv1d_16 (Conv1D)           (None, 60, 256)           131328    \n","_________________________________________________________________\n","max_pooling1d_16 (MaxPooling (None, 30, 256)           0         \n","_________________________________________________________________\n","lstm_13 (LSTM)               (None, 30, 256)           525312    \n","_________________________________________________________________\n","lstm_14 (LSTM)               (None, 30, 256)           525312    \n","_________________________________________________________________\n","lstm_15 (LSTM)               (None, 30, 256)           525312    \n","_________________________________________________________________\n","lstm_16 (LSTM)               (None, 256)               525312    \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 2)                 258       \n","=================================================================\n","Total params: 2,832,242\n","Trainable params: 2,682,242\n","Non-trainable params: 150,000\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lvAi-DgwXtNU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"outputId":"015fb94d-6906-47a0-ff08-464e9f7b3901","executionInfo":{"status":"error","timestamp":1591817535187,"user_tz":-330,"elapsed":994,"user":{"displayName":"Shubham Kumar","photoUrl":"","userId":"13299555443270476721"}}},"source":["model.fit(x_train, y_train,\n","                              validation_data=(x_test, y_test),\n","                              epochs=5,\n","                              batch_size=128\n","                              )\n"],"execution_count":22,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-9ddd7e958610>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                               )\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_4 to have shape (1,) but got array with shape (2,)"]}]},{"cell_type":"code","metadata":{"id":"P9a_mkD_XtHq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":231},"outputId":"b4769e47-3f40-4f37-f56e-9fe007ec37c4","executionInfo":{"status":"error","timestamp":1591817820759,"user_tz":-330,"elapsed":86770,"user":{"displayName":"Shubham Kumar","photoUrl":"","userId":"13299555443270476721"}}},"source":["predictions = model.predict_classes(x_test)\n","\n","cm = confusion_matrix(y_test, predictions, labels=[0,1])\n","title = 'Confusion matrix'\n","cmap = plt.cm.Blues\n","classes=[\"negative\",\"positive\"]\n","plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","plt.title(title)\n","plt.colorbar()\n","tick_marks = np.arange(len(classes))\n","plt.xticks(tick_marks, classes, rotation=45)\n","plt.yticks(tick_marks, classes)\n","\n","fmt = '.2f'\n","thresh = cm.max() / 2.\n","for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","    plt.text(j, i, format(cm[i, j], fmt),\n","             horizontalalignment=\"center\",\n","             color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","plt.ylabel('True label')\n","plt.xlabel('Predicted label')\n","plt.tight_layout()\n","plt.show()"],"execution_count":28,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-4904112d63cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Confusion matrix'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"]}]},{"cell_type":"code","metadata":{"id":"B3hEdhxHXtCo","colab_type":"code","colab":{}},"source":[" loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n","print('Test Loss: {}'.format(loss))\n","print('Test Accuracy: {}'.format(accuracy))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v_mRAMmiXs3x","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rJvsWE4zXs1i","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kaKR-ourXszU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_cDrhWqHXsuX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}