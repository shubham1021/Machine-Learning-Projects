{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN using Elmo.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMbCJ7iyNbrMH5efURLTEzQ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"mKfXK67erbS1","colab_type":"code","outputId":"50d9a511-e200-4138-aadf-f40e494ca18c","executionInfo":{"status":"ok","timestamp":1591819198400,"user_tz":-330,"elapsed":12927,"user":{"displayName":"Shubham Kumar","photoUrl":"","userId":"13299555443270476721"}},"colab":{"base_uri":"https://localhost:8080/","height":921}},"source":["!pip install tensorflow==1.15\n","!pip install \"tensorflow_hub>=0.6.0\"\n","!pip3 install tensorflow_text==1.15"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow==1.15 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.29.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.1)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.2)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.5)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.34.2)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.0.8)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.2.1)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.10.0)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.9.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (47.1.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.0)\n","Requirement already satisfied: tensorflow_hub>=0.6.0 in /usr/local/lib/python3.6/dist-packages (0.8.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub>=0.6.0) (3.10.0)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub>=0.6.0) (1.18.5)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub>=0.6.0) (1.12.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow_hub>=0.6.0) (47.1.1)\n","Requirement already satisfied: tensorflow_text==1.15 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n","Requirement already satisfied: tensorflow<1.16,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_text==1.15) (1.15.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.9.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.1.0)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.0)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.34.2)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.29.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.0.8)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.2.1)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.2.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.12.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.10.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.1.2)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.18.5)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.8.1)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.2.2)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.12.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (47.1.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.2.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZqE657cmtNMo","colab_type":"code","outputId":"1854ee29-63b4-4995-82e5-e065b3edf9b7","executionInfo":{"status":"ok","timestamp":1591819201839,"user_tz":-330,"elapsed":16347,"user":{"displayName":"Shubham Kumar","photoUrl":"","userId":"13299555443270476721"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from sklearn import metrics,preprocessing,model_selection\n","from sklearn.metrics import accuracy_score\n","import keras\n","from keras.layers import Input, Lambda, Dense\n","from keras.models import Model\n","import keras.backend as K\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import string\n","import pandas as pd\n","import re\n","import spacy\n","from nltk.corpus import stopwords\n","from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n","from spacy.lang.en import English\n","spacy.load('en')\n","parser = English()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n","/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n","  warnings.warn(message, FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"_s10seDlvCAr","colab_type":"code","colab":{}},"source":["import tensorflow_hub as hub\n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0nl7L62evFqt","colab_type":"code","colab":{}},"source":["embed = hub.Module(\"https://tfhub.dev/google/elmo/3\", trainable=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aaJ5LHM9vK_1","colab_type":"code","colab":{}},"source":["def ELMoEmbedding(x):\n","    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3pVDG0z61tZv","colab_type":"code","colab":{}},"source":["def elmo_vectors(x):\n","  embeddings = elmo(x.tolist(), signature=\"default\", as_dict=True)[\"elmo\"]\n","\n","  with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    sess.run(tf.tables_initializer())\n","    # return average of ELMo features\n","    return sess.run(tf.reduce_mean(embeddings,1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_-BFaQC4vQ-C","colab_type":"code","outputId":"bd5d4116-572c-4ab9-8baa-adafe0bd5742","executionInfo":{"status":"ok","timestamp":1591819201852,"user_tz":-330,"elapsed":16322,"user":{"displayName":"Shubham Kumar","photoUrl":"","userId":"13299555443270476721"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kIX_-l9wvrtc","colab_type":"code","outputId":"bb9c6a18-bb25-46cb-cb82-dd5308dcc9ac","executionInfo":{"status":"ok","timestamp":1591819203022,"user_tz":-330,"elapsed":17479,"user":{"displayName":"Shubham Kumar","photoUrl":"","userId":"13299555443270476721"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd '/content/drive/My Drive/'"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wVRjnKpZv3zy","colab_type":"code","outputId":"2e6b3b3b-6da0-42d1-9d40-6161195bca4e","executionInfo":{"status":"ok","timestamp":1591819205964,"user_tz":-330,"elapsed":20406,"user":{"displayName":"Shubham Kumar","photoUrl":"","userId":"13299555443270476721"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["# Importing dataset\n","reviews_df = pd.read_csv('Hotel_Reviews.csv')\n","print(reviews_df.dtypes)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Hotel_Address                                  object\n","Additional_Number_of_Scoring                    int64\n","Review_Date                                    object\n","Average_Score                                 float64\n","Hotel_Name                                     object\n","Reviewer_Nationality                           object\n","Negative_Review                                object\n","Review_Total_Negative_Word_Counts               int64\n","Total_Number_of_Reviews                         int64\n","Positive_Review                                object\n","Review_Total_Positive_Word_Counts               int64\n","Total_Number_of_Reviews_Reviewer_Has_Given      int64\n","Reviewer_Score                                float64\n","Tags                                           object\n","days_since_review                              object\n","lat                                           float64\n","lng                                           float64\n","dtype: object\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Wsp2rsHOv6M2","colab_type":"code","colab":{}},"source":["def clean(text):\n","    '''\n","    '''\n","    text = text.lower()\n","    text = text.replace(\"ain't\", \"am not\")\n","    text = text.replace(\"aren't\", \"are not\")\n","    text = text.replace(\"can't\", \"cannot\")\n","    text = text.replace(\"can't've\", \"cannot have\")\n","    text = text.replace(\"'cause\", \"because\")\n","    text = text.replace(\"could've\", \"could have\")\n","    text = text.replace(\"couldn't\", \"could not\")\n","    text = text.replace(\"couldn't've\", \"could not have\")\n","    text = text.replace(\"should've\", \"should have\")\n","    text = text.replace(\"should't\", \"should not\")\n","    text = text.replace(\"should't've\", \"should not have\")\n","    text = text.replace(\"would've\", \"would have\")\n","    text = text.replace(\"would't\", \"would not\")\n","    text = text.replace(\"would't've\", \"would not have\")\n","    text = text.replace(\"didn't\", \"did not\")\n","    text = text.replace(\"doesn't\", \"does not\")\n","    text = text.replace(\"don't\", \"do not\")\n","    text = text.replace(\"hadn't\", \"had not\")\n","    text = text.replace(\"hadn't've\", \"had not have\")\n","    text = text.replace(\"hasn't\", \"has not\")\n","    text = text.replace(\"haven't\", \"have not\")\n","    text = text.replace(\"haven't\", \"have not\")\n","    text = text.replace(\"haven't\", \"have not\")\n","    text = text.replace(\"haven't\", \"have not\")\n","    text = text.replace(\"he'd\", \"he would\")\n","    text = text.replace(\"haven't\", \"have not\")\n","    text = text.replace(\"he'd've\", \"he would have\")\n","    text = text.replace(\"'s\", \"\")\n","    text = text.replace(\"'t\", \"\")\n","    text = text.replace(\"'ve\", \"\")\n","    text = text.replace(\".\", \" . \")\n","    text = text.replace(\"!\", \" ! \")\n","    text = text.replace(\"?\", \" ? \")\n","    text = text.replace(\";\", \" ; \")\n","    text = text.replace(\":\", \" : \")\n","    text = text.replace(\",\", \" , \")\n","    text = text.replace(\"´\", \"\")\n","    text = text.replace(\"‘\", \"\")\n","    text = text.replace(\"’\", \"\")\n","    text = text.replace(\"“\", \"\")\n","    text = text.replace(\"”\", \"\")\n","    text = text.replace(\"\\'\", \"\")\n","    text = text.replace(\"\\\"\", \"\")\n","    text = text.replace(\"-\", \"\")\n","    text = text.replace(\"–\", \"\")\n","    text = text.replace(\"—\", \"\")\n","    text = text.replace(\"[\", \"\")\n","    text = text.replace(\"]\",\"\")\n","    text = text.replace(\"{\",\"\")\n","    text = text.replace(\"}\", \"\")\n","    text = text.replace(\"/\", \"\")\n","    text = text.replace(\"|\", \"\")\n","    text = text.replace(\"(\", \"\")\n","    text = text.replace(\")\", \"\")\n","    text = text.replace(\"$\", \"\")\n","    text = text.replace(\"+\", \"\")\n","    text = text.replace(\"*\", \"\")\n","    text = text.replace(\"%\", \"\")\n","    text = text.replace(\"#\", \"\")\n","    text = text.replace(\"\\n\", \" \\n \")\n","    text = text.replace(\"\\n\", \"\")\n","    text = text.replace(\"_\", \" _ \")\n","    text = text.replace(\"_\", \"\")\n","    text = ''.join([i for i in text if not i.isdigit()])\n","\n","    return text\n","\n","positive_reviews = reviews_df['Positive_Review'].values\n","negative_reviews = reviews_df['Negative_Review'].values\n","\n","cleaned_positive_reviews = [clean(r) for r in positive_reviews] \n","cleaned_negative_reviews = [clean(r) for r in negative_reviews] \n","\n","reviews_df['Positive_Review'] = cleaned_positive_reviews\n","reviews_df['Negative_Review'] = cleaned_negative_reviews"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i-5jtuFLv835","colab_type":"code","colab":{}},"source":["# Shuffling data\n","reviews_df = reviews_df.sample(frac=1).reset_index(drop=True)\n","\n","# Extracting all text\n","positive_reviews = reviews_df['Positive_Review'].values\n","negative_reviews = reviews_df['Negative_Review'].values\n","reviews_text = []\n","\n","for p,n in zip(positive_reviews, negative_reviews) : \n","    if p in ['na', 'nothing', 'none', 'n a', 'no', 'no positive', 'no negative'] : \n","        reviews_text.append(n)\n","    elif n in ['na', 'nothing', 'none', 'n a', 'no', 'no positive', 'no negative'] : \n","        reviews_text.append(p)\n","    else : \n","        reviews_text.append(n)\n","        reviews_text.append(p)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M9UHrTyZv_om","colab_type":"code","colab":{}},"source":["# Preprocessing training data\n","training_df = reviews_df.loc[:10000]\n","positive_reviews_filtered = training_df['Positive_Review'].values\n","negative_reviews_filtered = training_df['Negative_Review'].values\n","training_reviews = []\n","labels = []\n","\n","for idx,(p,n) in enumerate(zip(positive_reviews_filtered, negative_reviews_filtered)) : \n","    if p in ['na', 'nothing', 'none', 'n a', 'no', 'no positive', 'no negative'] : \n","        training_reviews.append(n)\n","        labels.append(0)\n","    elif n in ['na', 'nothing', 'none', 'n a', 'no', 'no positive', 'no negative'] :\n","        training_reviews.append(p)\n","        labels.append(1)\n","    else :\n","        training_reviews.append(n)\n","        labels.append(0)\n","        training_reviews.append(p)\n","        labels.append(1)\n","\n","# Creating datasets\n","dict1 ={\n","    'reviews' : training_reviews,\n","    'labels' : labels\n","}\n","sentiment_df = pd.DataFrame.from_dict(dict1)\n","\n","\n","dict2 ={\n","    'reviews_text' : reviews_text\n","}\n","reviews_text_df = pd.DataFrame.from_dict(dict2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"69t6WSB9wCl6","colab_type":"code","colab":{}},"source":["#one -hot encoding\n","def encode(le_enc, labels):\n","    enc = le_enc.transform(labels)\n","    return keras.utils.to_categorical(enc)\n","\n","def decode(le_enc, one_hot):\n","    dec = np.argmax(one_hot, axis=1)\n","    return le_enc.inverse_transform(dec)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gwb_H6xXwY8_","colab_type":"code","colab":{}},"source":["X = sentiment_df['reviews'].tolist()\n","y = sentiment_df['labels'].tolist()\n","\n","# Lebel encoding\n","le_enc = preprocessing.LabelEncoder()\n","le_enc.fit(y)\n","\n","y_en = encode(le_enc, y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cUB7r9hAxZLI","colab_type":"code","colab":{}},"source":["x_train, x_test, y_train, y_test = model_selection.train_test_split(np.asarray(X), np.asarray(y_en), test_size=0.2, random_state=42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DkDetUmGxd8p","colab_type":"code","outputId":"fb2ef6b8-c4b6-4a8b-c50d-a7ca973a94a1","executionInfo":{"status":"ok","timestamp":1591819228912,"user_tz":-330,"elapsed":43300,"user":{"displayName":"Shubham Kumar","photoUrl":"","userId":"13299555443270476721"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x_train.shape"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(13464,)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"jd1Fy9gQxjTS","colab_type":"code","outputId":"a8d791d5-74be-4f1b-e9c4-30b8997f72c5","colab":{"base_uri":"https://localhost:8080/","height":700},"executionInfo":{"status":"error","timestamp":1591819646708,"user_tz":-330,"elapsed":194427,"user":{"displayName":"Shubham Kumar","photoUrl":"","userId":"13299555443270476721"}}},"source":["# Build Model\n","input_text = Input(shape=(1,), dtype=tf.string)\n","embedding = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n","dense = Dense(256, activation='relu')(embedding)\n","pred = Dense(2, activation='softmax')(dense)\n","model = Model(inputs=[input_text], outputs=pred)\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","with tf.Session() as session:\n","    K.set_session(session)\n","    session.run(tf.global_variables_initializer())  \n","    session.run(tf.tables_initializer())\n","    history = model.fit(x_train, y_train, epochs=3, batch_size=128)\n","    model.save_weights('./response-elmo-model.h5')\n","\n","with tf.Session() as session:\n","    K.set_session(session)\n","    session.run(tf.global_variables_initializer())\n","    session.run(tf.tables_initializer())\n","    model.load_weights('./response-elmo-model.h5')  \n","    predicts = model.predict(x_test, batch_size=128)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/3\n","  384/13464 [..............................] - ETA: 3:12:36 - loss: 0.6095 - accuracy: 0.7109"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-a2b35ff49598>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./response-elmo-model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"qLX31VTPxzbU","colab_type":"code","colab":{}},"source":["# decode test labels\n","y_test = decode(le_enc, y_test)\n","# decode predicted labels\n","y_preds = decode(le_enc, predicts)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cGgLhp-Bx0Yu","colab_type":"code","colab":{}},"source":["print(metrics.confusion_matrix(y_test, y_preds))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Km1Iy1Cx0jR","colab_type":"code","colab":{}},"source":["print(metrics.classification_report(y_test, y_preds))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ThbJ1TTxx0eP","colab_type":"code","colab":{}},"source":["print(\"Accuracy of ELMO is:\",accuracy_score(y_test,y_preds))"],"execution_count":0,"outputs":[]}]}